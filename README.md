# ğŸ§ whisperpyannote â€” Transcription & Diarisation Audio/VidÃ©o

**whisperpyannote** est un script Python de **transcription automatique** et de **diarisation (sÃ©paration des voix)** Ã  partir de fichiers **audio ou vidÃ©o**, combinant la puissance de [OpenAI Whisper](https://github.com/openai/whisper) et [Pyannote Audio 3.0](https://github.com/pyannote/pyannote-audio).

> Ce projet sâ€™appuie sur [OpenAI Whisper](https://github.com/openai/whisper) pour la transcription et sur [Pyannote Audio](https://github.com/pyannote/pyannote-audio) pour la diarisation des locuteurs.  
> Merci aux auteurs de ces deux projets open source pour leur travail.

---

## âœ¨ FonctionnalitÃ©s

- ğŸ¥ Extraction automatique de lâ€™audio depuis les vidÃ©os (via **FFmpeg**)  
- ğŸ”„ Conversion en **mono 16 kHz** pour une compatibilitÃ© optimale  
- ğŸ“ Transcription haute qualitÃ© avec **Whisper (OpenAI)**  
- ğŸ—£ï¸ Diarisation prÃ©cise des locuteurs avec **Pyannote 3.0**  
- â³ RÃ©sumÃ© du temps de parole par speaker  
- ğŸ“œ Fusion propre des segments par locuteur  
- ğŸ“Š Statistiques globales (durÃ©e totale, nombre de speakers, moyenne)  
- ğŸ“‚ Export `.txt` avec horodatage + speakers  
- ğŸ“ˆ Suivi en temps rÃ©el via `tqdm`

---

## ğŸ™ï¸ Outils recommandÃ©s pour la capture audio et vidÃ©o

Pour enregistrer vos conversations, rÃ©unions ou appels avant transcription :

### ğŸŸ£ [OBS Studio](https://obsproject.com/)
Logiciel gratuit et open source pour **capturer la vidÃ©o et lâ€™audio** de votre Ã©cran, webcam ou applications.  
Il permet dâ€™enregistrer des visioconfÃ©rences, des interviews, des streams, etc.  
Les fichiers gÃ©nÃ©rÃ©s (`.mp4`, `.mkv`, `.mov`) sont directement compatibles avec **whisperpyannote**.

### âš« [BlackHole (macOS uniquement)](https://existential.audio/blackhole/)
Pilote audio virtuel gratuit pour **capturer lâ€™audio interne du systÃ¨me** (sons de lâ€™ordinateur).  
IdÃ©al pour enregistrer le son dâ€™une visioconfÃ©rence, dâ€™une vidÃ©o YouTube ou dâ€™une rÃ©union Zoom.  
Peut Ãªtre sÃ©lectionnÃ© comme source audio dans OBS pour combiner le **micro** et le **son du systÃ¨me**.

ğŸ’¡ *Avec OBS + BlackHole, vous pouvez enregistrer simultanÃ©ment votre voix et le son du systÃ¨me, puis passer le fichier rÃ©sultant Ã  `whisperpyannote` pour transcription et diarisation.*

---

## ğŸš€ Installation

### 1ï¸âƒ£ Cloner le dÃ©pÃ´t
```bash
git clone https://github.com/nantaidsl95/whisperpyannote.git
cd whisperpyannote
```

### 2ï¸âƒ£ Installer FFmpeg

FFmpeg est indispensable pour extraire et convertir lâ€™audio.

**Linux (Ubuntu/Debian)**
```bash
sudo apt update && sudo apt install ffmpeg
```

**macOS (Homebrew)**
```bash
brew install ffmpeg
```

**Windows**
1. TÃ©lÃ©chargez une version sur [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)  
2. Ajoutez le dossier `bin/` Ã  votre variable dâ€™environnement **PATH**  
3. VÃ©rifiez :
   ```powershell
   ffmpeg -version
   ```

âœ… Vous devez pouvoir exÃ©cuter `ffmpeg` depuis le terminal avant de lancer le script.

---

### 3ï¸âƒ£ CrÃ©er un environnement virtuel (recommandÃ©)
```bash
python3 -m venv venv
source venv/bin/activate
```
*(Sous Windows)* :
```powershell
venv\Scripts\activate
```

### 4ï¸âƒ£ Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

**Principaux packages :**
- `whisper`  
- `pyannote.audio`  
- `tqdm`  
- `ffmpeg-python`  
- `torch`  
- `numpy`

---

## ğŸ”‘ AccÃ¨s Hugging Face (obligatoire pour Pyannote)

Le modÃ¨le `pyannote/speaker-diarization-3.0` nÃ©cessite un **jeton dâ€™accÃ¨s personnel**.

1. Connectez-vous sur [https://huggingface.co/](https://huggingface.co/)  
2. Ouvrez la page du modÃ¨le :  
   ğŸ‘‰ [https://huggingface.co/pyannote/speaker-diarization-3.0](https://huggingface.co/pyannote/speaker-diarization-3.0)  
3. Cliquez sur **â€œAccess requestâ€** et acceptez les conditions.  
4. CrÃ©ez un token ici : [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)  
5. Exportez-le dans votre terminal :

```bash
export HUGGINGFACE_TOKEN="votre_token_ici"
```
Sous PowerShell :
```powershell
$env:HUGGINGFACE_TOKEN="votre_token_ici"
```

âš ï¸ Sans ce jeton, la partie **diarisation** Ã©chouera avec une erreur `403 Unauthorized`.

---

## ğŸ› ï¸ Utilisation

### Commande de base :
```bash
python whisperpyannote.py input_audio_or_video.mp4 output.txt
```

### Options disponibles :

| Option | Description | DÃ©faut |
|:--|:--|:--|
| `input_path` | Fichier audio ou vidÃ©o Ã  traiter | *obligatoire* |
| `output_file` | Fichier texte de sortie | *obligatoire* |
| `--whisper_model` | ModÃ¨le Whisper Ã  utiliser : `tiny`, `base`, `small`, `medium`, `large`, `turbo` | `turbo` |
| `--keep_temp` | Conserve les fichiers audio temporaires | *dÃ©sactivÃ©* |

---

### ğŸ’¡ Exemples

#### ğŸ™ï¸ Transcription dâ€™un fichier audio
```bash
python whisperpyannote.py podcast.wav transcription.txt
```

#### ğŸ¥ Transcription dâ€™une vidÃ©o avec conservation de lâ€™audio temporaire
```bash
python whisperpyannote.py interview.mp4 transcription.txt --keep_temp
```

---

## ğŸ“œ Exemple de sortie

```
â³ Temps de parole par speaker :
ğŸ—£ï¸ Speaker A: 00:12:34
ğŸ—£ï¸ Speaker B: 00:08:45

[00:00:01 - 00:00:05] ğŸ—£ï¸ Speaker A: Bonjour Ã  tous !
[00:00:06 - 00:00:10] ğŸ—£ï¸ Speaker B: Salut, comment Ã§a va ?
[00:00:11 - 00:00:18] ğŸ—£ï¸ Speaker A: TrÃ¨s bien, merci. On commence ?
...
```

Et dans la console :
```
ğŸ“Š RÃ©sumÃ© global :
- DurÃ©e totale analysÃ©e : 00:21:19
- Nombre de speakers : 2
- DurÃ©e moyenne par speaker : 00:10:39
```

---

## ğŸ§° DÃ©pannage

| ProblÃ¨me | Solution |
|:--|:--|
| `ffmpeg not found` | Installez FFmpeg et ajoutez-le au PATH |
| `403 Unauthorized` (Pyannote) | Votre token nâ€™a pas accÃ¨s au modÃ¨le â€” demandez lâ€™accÃ¨s sur Hugging Face |
| Transcription lente | Essayez un modÃ¨le plus petit : `--whisper_model small` |
| Pas de GPU dÃ©tectÃ© | Whisper utilisera automatiquement le CPU |

---

## ğŸ“ Structure du projet

```
whisperpyannote/
â”œâ”€â”€ whisperpyannote.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```

---

## ğŸ§© Technologies utilisÃ©es

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Pyannote Audio 3.0](https://github.com/pyannote/pyannote-audio)
- [FFmpeg](https://ffmpeg.org/)
- [tqdm](https://github.com/tqdm/tqdm)
- [OBS Studio](https://obsproject.com/)
- [BlackHole (macOS)](https://existential.audio/blackhole/)

---

## ğŸ“„ Licence

Projet sous licence **MIT** â€” voir [LICENSE](./LICENSE).

---

## ğŸ‘¤ Auteur

Projet dÃ©veloppÃ© par **Marc Delage**  
GitHub â†’ [nantaidsl95](https://github.com/nantaidsl95)
