# ğŸ§ whisperpyannote â€” Audio & Video Transcription + Speaker Diarization

![License](https://img.shields.io/badge/License-MIT-green)
![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Whisper](https://img.shields.io/badge/Whisper-STT-orange)
![Pyannote](https://img.shields.io/badge/Pyannote-Diarization-purple)
![Status](https://img.shields.io/badge/Status-Active-success)
![PRs](https://img.shields.io/badge/PRs-Welcome-brightgreen)

**whisperpyannote** is a Python script that performs:

- ğŸ“ automatic speech transcription  
- ğŸ—£ï¸ speaker diarization (who speaks when)  
- ğŸ¥ on both audio and video files  

It combines **Whisper (OpenAI)** for transcription and **Pyannote Audio** for speaker identification.

ğŸ”— Whisper â†’ https://github.com/openai/whisper  
ğŸ”— Pyannote community diarization model â†’ https://huggingface.co/pyannote/speaker-diarization-community-1  

---

## ğŸ™ Acknowledgements

This project uses two major open-source components:

- **Whisper (OpenAI)** â€” MIT License  
- **Pyannote Audio** and the model **speaker-diarization-community-1** â€” MIT License  

Thanks to their authors, maintainers, and contributors for making high-quality open models available to everyone.

---

## âœ¨ Features

- ğŸ¥ Automatic audio extraction from videos  
- ğŸ”„ Conversion to mono 16 kHz  
- ğŸ“ Whisper transcription  
- ğŸ—£ï¸ Pyannote diarization  
- ğŸ§  Smart merging of segments  
- â³ Speaking time per speaker  
- ğŸ“œ Clean final transcript  
- ğŸ“ˆ Progress bars with tqdm  

---

# ğŸ™ï¸ Recording with OBS (recommended)

Steps:

1. Install OBS: https://obsproject.com/  
2. Add **Display Capture** or **Window Capture**  
3. Add **Audio Input Capture** (microphone)  
4. Optional: capture system audio  
   - macOS â†’ install **BlackHole** (https://existential.audio/blackhole/)  
   - Windows â†’ enable **Stereo Mix** or use **VB-Cable**  
5. Record in MP4 or MKV  
6. Use the recorded file with `whisperpyannote`

OBS recordings (.mp4, .mov, .mkv) work perfectly.

---

## ğŸš€ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/nantaidsl95/whisperpyannote.git
cd whisperpyannote
```

### 2ï¸âƒ£ Install FFmpeg  

### 3ï¸âƒ£ Create a virtual environment
```bash
python3 -m venv venv
source venv/bin/activate
```

### 4ï¸âƒ£ Install Python dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Hugging Face Token (required for Pyannote)

1. Request access: https://huggingface.co/pyannote/speaker-diarization-community-1  
2. Create a token: https://huggingface.co/settings/tokens  
3. Export it:

```bash
export HUGGINGFACE_TOKEN="your_token"
```

---

# ğŸ› ï¸ Full CLI Options

### Required arguments

| Argument | Description |
|---------|-------------|
| `input_path` | Audio/video file to process |
| `output_file` | Output text file |

---

### Transcription & diarization options

| Option | Description | Values |
|--------|-------------|--------|
| `--whisper_model` | Whisper model | tiny, base, small, medium, large, turbo |
| `--language` | Force transcription language | en, fr, deâ€¦ |

---

### Exclusive modes

| Option | Description |
|--------|-------------|
| `--transcription_only` | Only transcription |
| `--diarization_only` | Only diarization |

---

### Token management

| Option | Description |
|--------|-------------|
| `--hf_token` | Provide HF token directly |
| `--ask_token` | Force interactive prompt |

Also detected automatically:
- `HF_TOKEN`
- `HUGGINGFACE_TOKEN`

---

### Temporary files

| Option | Description |
|--------|-------------|
| `--keep_temp` | Keep temporary WAV files |

---

# ğŸš€ Usage Examples

```bash
python whisperpyannote.py input.mp4 output.txt
python whisperpyannote.py audio.wav output.txt --transcription_only
python whisperpyannote.py audio.wav output.txt --whisper_model medium
python whisperpyannote.py audio.wav output.txt --language fr
python whisperpyannote.py audio.wav output.txt --hf_token "hf_xxx"
```

---

## ğŸ“œ Example Output

```
â³ Speaking time per speaker:
SPEAKER_00: 00:12:34
SPEAKER_01: 00:08:45

[00:00:01â€“00:00:05] SPEAKER_00: Hello everyone!
[00:00:06â€“00:00:10] SPEAKER_01: Hi, how are you?
```

---

## ğŸ“ Project Structure

```
whisperpyannote/
â”œâ”€â”€ whisperpyannote.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```

---

## ğŸ“„ License

This project is distributed under the MIT License.  
See the [LICENSE](./LICENSE) file for details.

---

## ğŸ‘¤ Author

Developed by **Marc Delage**  
GitHub â†’ https://github.com/nantaidsl95
