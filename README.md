# Transcription & Diarisation Audio/VidÃ©o

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)  
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)

Python script for automatic audio/video **transcription** and **speaker diarization**, using [OpenAI Whisper](https://github.com/openai/whisper) and [pyannote-audio](https://github.com/pyannote/pyannote-audio).

---

## âœ¨ Features
- ğŸ¥ Automatic audio extraction from video files (via **FFmpeg**)  
- ğŸ”„ Conversion to **16kHz mono** audio for compatibility  
- ğŸ“ High-quality transcription with OpenAI Whisper  
- ğŸ—£ï¸ Speaker diarization using Pyannote 3.0  
- â³ Per-speaker talk time summary  
- ğŸ“Š Global analysis (duration, number of speakers, averages)  
- ğŸ“‚ Output as a clean `.txt` file (timestamps + speakers)  
- ğŸ“ˆ Progress bar with `tqdm`  

---

## ğŸš€ Installation

### 1. Clone this repository
```bash
git clone https://github.com/<your-username>/transcription-diarisation.git
cd transcription-diarisation
```

---

### 2. Install FFmpeg (required)

This project relies on **FFmpeg** to extract and convert audio.  

- **Linux (Debian/Ubuntu)**  
  ```bash
  sudo apt update
  sudo apt install ffmpeg
  ```

- **macOS (Homebrew)**  
  ```bash
  brew install ffmpeg
  ```

- **Windows**  
  1. Download the FFmpeg build: [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)  
  2. Extract it and add the `bin/` folder to your **PATH**  
  3. Test installation:  
     ```powershell
     ffmpeg -version
     ```

âœ… After this, `ffmpeg` should be accessible from the command line.

---

### 3. Create a Virtual Environment (Recommended)
```bash
python3 -m venv venv
source venv/bin/activate
```
(Windows users):  
```bash
venv\Scripts\activate
```

---

### 4. Install Python dependencies
```bash
pip install -r requirements.txt
```

Dependencies include:  
- `whisper`  
- `pyannote.audio`  
- `tqdm`  

---

## ğŸ”‘ Hugging Face Access Token

This script uses the `pyannote/speaker-diarization-3.0` model, which requires explicit access.  

1. Visit: [https://huggingface.co/pyannote/speaker-diarization-3.0](https://huggingface.co/pyannote/speaker-diarization-3.0)  
2. Click on **"Agree and access"**  
3. Create a token: [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)  
4. Export it in your terminal:  

```bash
export HUGGINGFACE_TOKEN="your_token_here"
```
Windows (PowerShell):  
```powershell
$env:HUGGINGFACE_TOKEN="your_token_here"
```

âš ï¸ Without this step, diarization will fail with a `403 Unauthorized` error.  

---

## ğŸ› ï¸ Usage

Basic command:
```bash
python transcribe_diarize.py input_audio_or_video.mp4 output.txt
```

Options:
- `--whisper_model`: `tiny`, `base`, `small`, `medium`, `large`, `turbo` (default: `turbo`)  
- `--keep_temp`: keep temporary audio files  

Example:
```bash
python transcribe_diarize.py interview.mp4 transcription.txt --whisper_model medium --keep_temp
```

---

## ğŸ“œ Example Output

After processing, youâ€™ll get a text file like this:

```
â³ Temps de parole par speaker :
ğŸ—£ï¸ Speaker A: 00:12:34
ğŸ—£ï¸ Speaker B: 00:08:45

[00:00:01 - 00:00:05] ğŸ—£ï¸ Speaker A: Bonjour Ã  tous !
[00:00:06 - 00:00:10] ğŸ—£ï¸ Speaker B: Salut, comment Ã§a va ?
[00:00:11 - 00:00:18] ğŸ—£ï¸ Speaker A: TrÃ¨s bien, merci. On commence ?
[00:00:19 - 00:00:25] ğŸ—£ï¸ Speaker B: Oui, allons-y.
...
```

And a global summary in the console:

```
ğŸ“Š RÃ©sumÃ© global :
- DurÃ©e totale analysÃ©e : 00:21:19
- Nombre de speakers : 2
- DurÃ©e moyenne par speaker : 00:10:39
```

---

## ğŸ“‚ Project Structure
```
transcription-diarisation/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ transcribe_diarize.py
```

---

## ğŸ§© Technologies Used
- [OpenAI Whisper](https://github.com/openai/whisper)  
- [pyannote-audio](https://github.com/pyannote/pyannote-audio)  
- [FFmpeg](https://ffmpeg.org/)  

---

## ğŸ¤ Contributing

Contributions are welcome!  

1. Fork this repository  
2. Create a branch (`git checkout -b feature/MyFeature`)  
3. Commit your changes (`git commit -m 'Add MyFeature'`)  
4. Push to the branch (`git push origin feature/MyFeature`)  
5. Open a Pull Request  

---

## ğŸ“„ License

This project is licensed under the MIT License.  
See the [LICENSE](./LICENSE) file for more details.  

---

## ğŸ™Œ Author

Project developed by **Marc Delage**.  
