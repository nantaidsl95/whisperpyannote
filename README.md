# WhisperPyannote

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE) 
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)

Script Python pour transcrire et diariser automatiquement des fichiers audio ou vidÃ©o, en utilisant [OpenAI Whisper](https://github.com/openai/whisper) et [pyannote-audio](https://github.com/pyannote/pyannote-audio).

---

## âœ¨ FonctionnalitÃ©s

- Extraction automatique de l'audio depuis une vidÃ©o.
- Conversion au format 16kHz mono pour Whisper et Pyannote.
- Transcription de haute qualitÃ© avec OpenAI Whisper.
- Diarisation des locuteurs avec Pyannote 3.0.
- RÃ©sumÃ© du temps de parole par speaker.
- Fichier texte de sortie lisible et horodatÃ©.
- Barre de progression (`tqdm`) pour visualiser l'avancement.

---

## ğŸš€ Installation

Cloner ce dÃ©pÃ´t :
```bash
git clone https://github.com/nantaidsl95/whisperpyannote.git
cd whisperpyannote
```

Installer les dÃ©pendances :
```bash
pip install -r requirements.txt
```

PrÃ©requis :
- Python 3.8 ou supÃ©rieur
- `ffmpeg` installÃ© sur votre systÃ¨me
- Un compte Hugging Face valide (pour pyannote)

---

## ğŸ”‘ Autoriser l'accÃ¨s Hugging Face

Le script utilise le modÃ¨le `pyannote/speaker-diarization-3.0` hÃ©bergÃ© sur Hugging Face, qui nÃ©cessite un accÃ¨s spÃ©cifique.

Avant la premiÃ¨re utilisation :

1. Allez sur [https://huggingface.co/pyannote/speaker-diarization-3.0](https://huggingface.co/pyannote/speaker-diarization-3.0) et cliquez sur **"Agree and access"** pour accepter les conditions d'utilisation.
2. CrÃ©ez un token Hugging Face personnel ici : [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
3. Dans votre terminal, exportez votre token :

```bash
export HUGGINGFACE_TOKEN="votre_token_ici"
```

Vous Ãªtes maintenant prÃªt Ã  utiliser le script.

---

## ğŸ› ï¸ Utilisation

Commande de base :
```bash
python transcribe_and_diarize.py input_audio_or_video.mp4 output.txt
```

Options disponibles :
- `--whisper_model` : choisir le modÃ¨le Whisper (`tiny`, `base`, `small`, `medium`, `large`, `turbo`) â€” par dÃ©faut `turbo`
- `--keep_temp` : conserver les fichiers temporaires gÃ©nÃ©rÃ©s

Exemple complet :
```bash
python transcribe_and_diarize.py interview.mp4 transcription.txt --whisper_model medium --keep_temp
```

---

## ğŸ“‚ Architecture du projet

```
whisperpyannote/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ setup.py
â”œâ”€â”€ transcribe_and_diarize.py
â”œâ”€â”€ whisperpyannote/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ transcription.py
â”‚   â””â”€â”€ diarization.py
â””â”€â”€ examples/
    â””â”€â”€ (fichiers audio/vidÃ©o exemples)
```

---

## ğŸ§© Technologies utilisÃ©es

Ce projet utilise :

- [OpenAI Whisper](https://github.com/openai/whisper) (licence MIT)
- [pyannote-audio](https://github.com/pyannote/pyannote-audio) dÃ©veloppÃ© par l'UniversitÃ© de Lorraine (licence MIT)

Merci aux Ã©quipes respectives pour leurs travaux exceptionnels !

---

## ğŸ¤ Contribuer

Les contributions sont les bienvenues !

Merci de suivre ces Ã©tapes :
1. Forker ce dÃ©pÃ´t.
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`).
3. Commiter vos modifications (`git commit -m 'Add some AmazingFeature'`).
4. Pousser vers la branche (`git push origin feature/AmazingFeature`).
5. CrÃ©er une Pull Request.

---

## ğŸ“„ Licence

Ce projet est sous licence MIT.  
Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ™Œ Auteur

Projet dÃ©veloppÃ© par [Marc Delage](https://github.com/nantaidsl95).
